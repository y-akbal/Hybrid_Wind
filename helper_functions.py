#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Dec 28 15:35:01 2022

@author: sahmaran
"""
import os
import pandas as pd
import numpy as np
from time import localtime

def write_log(a:str, file = "log.txt") -> None:
    """
    used for causal logging to txt file, str goes in log.txt goes out with local time!
    """
    lt = list(localtime()) ### local time comes here
    lc = str(lt[0])+"-"+str(lt[1])+"-"+str(lt[2])+"---"+str(lt[3])+":"+str(lt[4]) ### format the local time here!
    with open(file, mode = "a") as my_file:
        my_file.write(f"{lc}: \t{a}\n")



"""
Some preprocessing
"""
def return_files(): ### this guy is responsible for picking up the csv files with ws column in it!
    """
    returns: the list of files to be generated by the file and                         
    """
    files = []
    data = []
    w_files = []
    print("The following files found:")
    len__ = 0
    for file in os.listdir():
        if file.endswith(".csv"):
            try:
                m = pd.read_csv(file)["ws"]
                len_ = len(m)
                len__ += len_
                files.append(file)
                data.append(m)
                print(f"{file} of length {len_}")
            except KeyError:
                w_files.append(file)
            
    print(f"The total number of observations is {len__}, there are {len(files)} time series to be processed, {len(w_files)} csv files do not have column \'ws\'.")
    return files, data


class time_series_slices:  ### this dude is responsible for creating sliding windows for each time series.
    """
    creates a series of the data to be generated by the file and returns the time      
    """
    def __init__(self, length = 64):
        self.length = length
    ##     
    ##
    def __return_preprocessed_data(self, data__, **kwargs):
        """
        args: data_ = here assumed to be list of pd dataframes. **kwargs are to be passed to interpolation function!
        """ 
        data_ = [data.interpolate(**kwargs) for data in data__] ### get rid of nan values.
        data_ = [(data - data.mean())/(data.std()) for data in data_]
        cls_list = []  #### class values for different time series.
        total_length = sum([len(data) for data in data_]) ### overall length to be used by endog and exog.
        X = []
        y = []
        for j,data in enumerate(data_):
            for i in range(len(data)-self.length):
                X.append(np.array(data[i:i+self.length]))
                y.append(np.array(data[i+self.length]))
                cls_list.append(j)
        return np.array(X), np.array(y), np.array(cls_list)
    ##
    ##
    def __split_data(self, data_, alpha):
        """
        returns the splitted data
        """
        lens = [len(data) for data in data_]
        N_len = [int(alpha*N) for N in lens]
        data_train = [data[:N] for N, data in zip(N_len, data_)]
        data_test = [data[N:] for N, data in zip(N_len, data_)]
        for data in data_test:
            data.index = [i for i in range(len(data))]
        return data_train, data_test
    ##
    ##
    def fit_transform(self,data_, alpha = 0.8, **kwargs):
        assert isinstance(data_, list)
        assert all([isinstance(data, pd.Series) for data in data_])
        
        data_train, data_test = self.__split_data(data_, alpha)
        return self.__return_preprocessed_data(data_train, **kwargs), self.__return_preprocessed_data(data_test, **kwargs)
